{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.regularizers import l2\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n\n%matplotlib inline\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport sklearn.model_selection as ms\n\nsns.set(style='white', context='notebook', palette='deep')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data preparation","metadata":{}},{"cell_type":"code","source":"# Load the data\ntrain = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")\ntrain.shape, test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Checking for missing values**","metadata":{}},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Since, there is no missing data found, we can proceed further.*","metadata":{}},{"cell_type":"markdown","source":"**Separating data into features and labels**","metadata":{}},{"cell_type":"code","source":"y = train['label'].to_numpy()\ntrain = train.drop(columns=['label'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Getting common numpy values for the dataframe\nX = train.to_numpy()\ntest = test.to_numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Suppose there are values in the Dataframe or Series having dtypes float16 and float32, then after applying this method, all values will have a common dtype.*","metadata":{}},{"cell_type":"markdown","source":"**Reshaping**","metadata":{}},{"cell_type":"code","source":"X = X.reshape(-1,28,28,1)\ntest = test.reshape(-1,28,28,1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Normalization**","metadata":{}},{"cell_type":"code","source":"X = X/255.0\ntest = test/255.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*CNN converg faster on [0..1] data than on [0..255] and it's a lot easier to interpret also.*","metadata":{}},{"cell_type":"code","source":"indices = np.random.randint(low=0, high=42000, size=5)\nfor i in indices:\n    plt.figure()\n    plt.imshow(X[i,:,:,0], cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Label Encoding**","metadata":{}},{"cell_type":"code","source":"# Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\ny = to_categorical(y, 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Split training and validation set**","metadata":{}},{"cell_type":"code","source":"# Seed is set in order to retain consistent results\nnp.random.seed(1)\n\n# Train_test_split\nX_train, X_val, y_train, y_val = ms.train_test_split(X, y, test_size=0.1, random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Here, we have built a Sequential model with 5 convolution layers with the image size 28X28 and a Dense layer with 512 neurons. We have also specified callbacks based on validation accuracy(patience means process will come to a halt after the no. of epochs for which val_acc doesn't improve).**","metadata":{}},{"cell_type":"code","source":"# EarlyStopping and Reduce Learning Rate Callbacks\nmy_callback_es = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=5)\nmy_callback_rlr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', patience=2, factor=0.5, min_lr=0.00001, verbose=1)\n\nmodel = tf.keras.models.Sequential([\n    # The input shape is the desired size of the image 150x150 with 3 bytes color\n    # This is the first convolution layer\n    tf.keras.layers.Conv2D(64, (5,5), padding='same', activation='relu', input_shape=(28, 28, 1)),\n\n    # This is the second convolution layer\n    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu', strides=2),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    # This is the third convolution layer\n    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n    \n    # This is the fourth convolution layer\n    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu'),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    \n    # Flatten the results to feed into a DNN\n    tf.keras.layers.Flatten(),\n    \n    \n    # 512 neuron hidden layer\n    tf.keras.layers.Dense(512, activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(10, activation='softmax')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\nmodel.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[my_callback_es, my_callback_rlr], shuffle=True, batch_size=86)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend(loc=0)\nplt.figure()\n\nplt.plot(epochs, loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'b', label='Validation Loss')\nplt.ylim(top=1.0)\nplt.title('Training and validation loss')\nplt.legend(loc=0)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(test)\npredictions = predictions.argmax(axis=1)\nimageid = np.arange(1,28001)\noutput = pd.DataFrame({\"ImageId\": imageid,\"Label\": predictions})\noutput.to_csv('submissions1.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}